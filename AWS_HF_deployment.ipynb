{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment Models on Amazon Sagemaker"
      ],
      "metadata": {
        "id": "JjUqIb8VWQGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download necessary libraries\n",
        "!pip install sagemaker --upgrade"
      ],
      "metadata": {
        "id": "ovkXHz8dWgk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first getting the information regarding sagemaker session\n",
        "import sagemaker\n",
        "import boto3\n",
        "\n",
        "iam_client = sagemaker.client(\"iam\")\n",
        "role = iam_client.get_role(\"\")[\"Role\"][\"arn\"]\n",
        "\n",
        "sess = sagemaker.Session()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9hyRQ4TWQYH",
        "outputId": "1d6bf458-0d36-4950-e51c-2b80a666a199"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
            "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## There are Two options while deploying model\n",
        "  * model is trained on sagemaker\n",
        "  * model is present in HF hub"
      ],
      "metadata": {
        "id": "XX47kkdkXOuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When model is trained in sagemaker\n",
        "\n",
        "   * The model can be first trained and then deployed\n",
        "   * any model which is present in other lcation with AWS"
      ],
      "metadata": {
        "id": "lL1l6IfJXeUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploy after training"
      ],
      "metadata": {
        "id": "J2siziQpbKrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# -------------DEPLOY AFTER TRAINING ----------------\n",
        "# lets first train the model and then directly deploy\n",
        "\n",
        "\n",
        "from sagemaker.huggingface import HuggingFace\n",
        "\n",
        "# for training in sagemaker\n",
        "# follow the training large language models in sagemaker python notebook or repository\n",
        "# here we will just write basic training code\n",
        "\n",
        "############# pseudo code start ############\n",
        "\n",
        "# ------- create a huggingFaceEstimator -------------\n",
        "huggingfaceEstimator = HuggingFace()\n",
        "\n",
        "#------- Start training using the fit method ------------\n",
        "huggingfaceEstimator.fit()\n",
        "\n",
        "############ pseudo code end ############\n",
        "\n",
        "# now we will use the estimator to deploy the model that we trained\n",
        "predictor_pipeline = huggingfaceEstimator.deploy(initial_instance_count = 1,\n",
        "                            instance_type = \"chose your desired required instance\")\n",
        "\n",
        "# now we can just sent the input directory to the predictor_pipeline as its\n",
        "# ********** Inference Toolkit builds on top of the pipeline feature from ðŸ¤— Transformers *******\n",
        "\n",
        "input_data = {\n",
        "    \"inputs\" : \"sentence\"\n",
        "}\n",
        "\n",
        "predictor_pipeline.predict(input_data)"
      ],
      "metadata": {
        "id": "YUW8sewzWQan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------- DELETING THE ENDPOINT------------\n",
        "predictor_pipeline.delete_endpoint()\n"
      ],
      "metadata": {
        "id": "lFJ_nzo5WQdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploy trained model data present in s3"
      ],
      "metadata": {
        "id": "BBNCffUGbNfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you've already trained the model and saved it somewhere\n",
        "# then we can give the lcoation address/path of model data and tokenizer data\n",
        "\n",
        "# to deploy from model data we need to create HuggingFaceModel class\n",
        "from sagemaker.huggingface.model import HuggingfaceModel\n",
        "huggingfacemodel = HuggingFaceModel(\n",
        "    model_data = \"\",                  # path where you model is stored\n",
        "    role = role,\n",
        "    tranformers_version = \"\",\n",
        "    pytorch_version = \"\",\n",
        "    py_version = \"\"\n",
        ")\n",
        "\n",
        "# now you can deploy this model class\n",
        "predictor_pipeline = huggingfacemodel.deploy(\n",
        "                                  initial_instance_count = 1,\n",
        "                                  instance_type = \"your aws instance where you want to deploy\"\n",
        ")\n",
        "\n",
        "data = {\n",
        "    \"input\" : \"sentence\"\n",
        "}\n",
        "\n",
        "predictor_pipeline.predict(data)"
      ],
      "metadata": {
        "id": "Udiz-ZCeWQfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can delete the endpoint afterwards\n",
        "predictor_pipeline.delete_endpoint()"
      ],
      "metadata": {
        "id": "FaNkQWdkWQg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### deploying model from the HF hub"
      ],
      "metadata": {
        "id": "h4UFvS_VdsIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inorder to deploy from the huggingfacehug\n",
        "# we need to have the model_id from the hub\n",
        "\n",
        "# and we also need task for which we will be creating the pipeline\n",
        "# we set these variable as environment variables\n",
        "from sagemaker.huggingface.model import HuggingFaceModel\n",
        "\n",
        "hub = {\n",
        "    \"HF_MODEL_ID\" : \"\"\n",
        "    \"HF_TASK\" : \"\"\n",
        "}\n",
        "\n",
        "\n",
        "# create a huggingfacemodel class\n",
        "\n",
        "huggingfacemodel = HuggingFaceModel(\n",
        "    env = hub,\n",
        "    role = role,\n",
        "    transformers_version = \"\",\n",
        "    pytorch_version = \"\",\n",
        "    py_version = \"\"\n",
        ")\n",
        "\n",
        "# deploy it as endpoint\n",
        "prdictor_pipeline = huggingfacemodel.deploy(\n",
        "    initial_instance_count = 1,\n",
        "    instance_type = ''\n",
        ")\n",
        "\n",
        "data  = {\n",
        "    \"input\" : \"\",\n",
        "    \"context\" : \"\"\n",
        "}\n",
        "\n",
        "predictor_pipeline.predict(data)\n",
        "\n",
        "\n",
        "# dleete the endpoint later when not required\n",
        "predictor_pipeline.delete_endpoint()\n"
      ],
      "metadata": {
        "id": "8Tr31GX2WQjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run batch transform with ðŸ¤— Transformers and SageMaker"
      ],
      "metadata": {
        "id": "XTPyL4Dkk1_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you trained a model using the Hugging Face Estimator,\n",
        "# call the transformer() method to create a transform job for a model based on the training job\n",
        "\n",
        "# first call the transformer() function on the huggingfacemodel class object\n",
        "\n",
        "batch_job = huggingfaceestimator.transformer(\n",
        "    instance_count = \"\",\n",
        "    instance_type = \"\",\n",
        "    strategy = \"SingleRecord\" # process single record at a time\n",
        ")\n",
        "\n",
        "batch_job.transform(\n",
        "    data = \"s3 location where data is stored in json format\",\n",
        "    content_type = \"Application/json\",\n",
        "    split_type = \"Line\"\n",
        ")\n",
        "\n",
        "\n",
        "# the iput is in this format\n",
        "{\"inputs\":\"this movie is terrible\"}\n",
        "{\"inputs\":\"this movie is amazing\"}\n",
        "{\"inputs\":\"SageMaker is pretty cool\"}\n",
        "{\"inputs\":\"SageMaker is pretty cool\"}\n",
        "{\"inputs\":\"this movie is terrible\"}\n",
        "{\"inputs\":\"this movie is amazing\"}\n",
        "\n"
      ],
      "metadata": {
        "id": "uaw0FJxuWQk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-s5bjlVWQnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kWNGzbjWQpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HPACK9s7WQrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b66cTgQGWQsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFVw07XuWQvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJaVlXwOWQwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGtInl7aWQye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VRFRJTfPWQ0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qyprNik6WQ2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cupAlShwWQ5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LaW3mquoWQ8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WSJimyBeWQ_v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}